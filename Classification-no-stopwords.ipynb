{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading in the dataset, the 'Complete' column needs to be moved so that the train_test_split function is easier to deal with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "enron = pd.read_pickle(\"./enron_cleaned.pkl\")\n",
    "tags = pd.read_pickle(\"./pos_tags.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'caiso notice cmr recommrendation board approval market participant iso recommendation congestion management reform present approval iso governing board september post iso web site reminder informational conference call a.m. p.m. tomorrow august provide opportunity clarify content format ask board approve teleconference information follow call password leader byron woertz byron woertz director client relation '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron['Complete'][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Message-ID', 'Date', 'From', 'To', 'Subject', 'X-From', 'X-To', 'X-cc',\n",
       "       'X-bcc', 'X-Folder', 'X-Origin', 'X-FileName', 'content', 'user',\n",
       "       'Cat_1_level_1', 'Cat_1_level_2', 'Cat_1_weight', 'Cat_2_level_1',\n",
       "       'Cat_2_level_2', 'Cat_2_weight', 'Cat_3_level_1', 'Cat_3_level_2',\n",
       "       'Cat_3_weight', 'Cat_4_level_1', 'Cat_4_level_2', 'Cat_4_weight',\n",
       "       'Cat_5_level_1', 'Cat_5_level_2', 'Cat_5_weight', 'Cat_6_level_1',\n",
       "       'Cat_6_level_2', 'Cat_6_weight', 'Cat_7_level_1', 'Cat_7_level_2',\n",
       "       'Cat_7_weight', 'Cat_8_level_1', 'Cat_8_level_2', 'Cat_8_weight',\n",
       "       'Cat_9_level_1', 'Cat_9_level_2', 'Cat_9_weight', 'Cat_10_level_1',\n",
       "       'Cat_10_level_2', 'Cat_10_weight', 'Cat_11_level_1', 'Cat_11_level_2',\n",
       "       'Cat_11_weight', 'Cat_12_level_1', 'Cat_12_level_2', 'Cat_12_weight',\n",
       "       'labeled', 'Complete'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Complete</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>...</th>\n",
       "      <th>Cat_10_level_1</th>\n",
       "      <th>Cat_10_level_2</th>\n",
       "      <th>Cat_10_weight</th>\n",
       "      <th>Cat_11_level_1</th>\n",
       "      <th>Cat_11_level_2</th>\n",
       "      <th>Cat_11_weight</th>\n",
       "      <th>Cat_12_level_1</th>\n",
       "      <th>Cat_12_level_2</th>\n",
       "      <th>Cat_12_weight</th>\n",
       "      <th>labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>confidential employee informationlenhart also ...</td>\n",
       "      <td>&lt;9831685.1075855725804.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-03-15 14:45:00</td>\n",
       "      <td>frozenset({'phillip.allen@enron.com'})</td>\n",
       "      <td>frozenset({'todd.burke@enron.com'})</td>\n",
       "      <td>Re: Confidential Employee Information/Lenhart</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Todd Burke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>personal confidential compensation information...</td>\n",
       "      <td>&lt;21041312.1075855725847.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-03-15 14:11:00</td>\n",
       "      <td>frozenset({'phillip.allen@enron.com'})</td>\n",
       "      <td>frozenset({'kim.bolton@enron.com'})</td>\n",
       "      <td>RE: PERSONAL AND CONFIDENTIAL COMPENSATION INF...</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Kim Bolton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fw western wholesale activity gas &amp; power conf...</td>\n",
       "      <td>&lt;5907100.1075858639941.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-06-20 17:04:51</td>\n",
       "      <td>frozenset({'k..allen@enron.com'})</td>\n",
       "      <td>frozenset({'matt.smith@enron.com', 'matthew.le...</td>\n",
       "      <td>FW: Western Wholesale Activities - Gas &amp; Power...</td>\n",
       "      <td>Allen, Phillip K. &lt;/O=ENRON/OU=NA/CN=RECIPIENT...</td>\n",
       "      <td>Lenhart, Matthew &lt;/O=ENRON/OU=NA/CN=RECIPIENTS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fw western wholesale activity gas &amp; power conf...</td>\n",
       "      <td>&lt;26625142.1075858639964.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-06-20 17:09:00</td>\n",
       "      <td>frozenset({'k..allen@enron.com'})</td>\n",
       "      <td>frozenset({'matt.smith@enron.com', 'matthew.le...</td>\n",
       "      <td>FW: Western Wholesale Activities - Gas &amp; Power...</td>\n",
       "      <td>Allen, Phillip K. &lt;/O=ENRON/OU=NA/CN=RECIPIENT...</td>\n",
       "      <td>Lenhart, Matthew &lt;/O=ENRON/OU=NA/CN=RECIPIENTS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fw western wholesale activity gas &amp; power conf...</td>\n",
       "      <td>&lt;19730598.1075858642129.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-08-09 12:30:58</td>\n",
       "      <td>frozenset({'k..allen@enron.com'})</td>\n",
       "      <td>frozenset({'matt.smith@enron.com', 'm..tholt@e...</td>\n",
       "      <td>FW: Western Wholesale Activities - Gas &amp; Power...</td>\n",
       "      <td>Allen, Phillip K. &lt;/O=ENRON/OU=NA/CN=RECIPIENT...</td>\n",
       "      <td>Smith, Matt &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Complete  \\\n",
       "0  confidential employee informationlenhart also ...   \n",
       "1  personal confidential compensation information...   \n",
       "2  fw western wholesale activity gas & power conf...   \n",
       "3  fw western wholesale activity gas & power conf...   \n",
       "4  fw western wholesale activity gas & power conf...   \n",
       "\n",
       "                                      Message-ID                 Date  \\\n",
       "0   <9831685.1075855725804.JavaMail.evans@thyme>  2001-03-15 14:45:00   \n",
       "1  <21041312.1075855725847.JavaMail.evans@thyme>  2001-03-15 14:11:00   \n",
       "2   <5907100.1075858639941.JavaMail.evans@thyme>  2001-06-20 17:04:51   \n",
       "3  <26625142.1075858639964.JavaMail.evans@thyme>  2001-06-20 17:09:00   \n",
       "4  <19730598.1075858642129.JavaMail.evans@thyme>  2001-08-09 12:30:58   \n",
       "\n",
       "                                     From  \\\n",
       "0  frozenset({'phillip.allen@enron.com'})   \n",
       "1  frozenset({'phillip.allen@enron.com'})   \n",
       "2       frozenset({'k..allen@enron.com'})   \n",
       "3       frozenset({'k..allen@enron.com'})   \n",
       "4       frozenset({'k..allen@enron.com'})   \n",
       "\n",
       "                                                  To  \\\n",
       "0                frozenset({'todd.burke@enron.com'})   \n",
       "1                frozenset({'kim.bolton@enron.com'})   \n",
       "2  frozenset({'matt.smith@enron.com', 'matthew.le...   \n",
       "3  frozenset({'matt.smith@enron.com', 'matthew.le...   \n",
       "4  frozenset({'matt.smith@enron.com', 'm..tholt@e...   \n",
       "\n",
       "                                             Subject  \\\n",
       "0      Re: Confidential Employee Information/Lenhart   \n",
       "1  RE: PERSONAL AND CONFIDENTIAL COMPENSATION INF...   \n",
       "2  FW: Western Wholesale Activities - Gas & Power...   \n",
       "3  FW: Western Wholesale Activities - Gas & Power...   \n",
       "4  FW: Western Wholesale Activities - Gas & Power...   \n",
       "\n",
       "                                              X-From  \\\n",
       "0                                    Phillip K Allen   \n",
       "1                                    Phillip K Allen   \n",
       "2  Allen, Phillip K. </O=ENRON/OU=NA/CN=RECIPIENT...   \n",
       "3  Allen, Phillip K. </O=ENRON/OU=NA/CN=RECIPIENT...   \n",
       "4  Allen, Phillip K. </O=ENRON/OU=NA/CN=RECIPIENT...   \n",
       "\n",
       "                                                X-To X-cc  X-bcc   ...     \\\n",
       "0                                         Todd Burke  NaN    NaN   ...      \n",
       "1                                         Kim Bolton  NaN    NaN   ...      \n",
       "2  Lenhart, Matthew </O=ENRON/OU=NA/CN=RECIPIENTS...  NaN    NaN   ...      \n",
       "3  Lenhart, Matthew </O=ENRON/OU=NA/CN=RECIPIENTS...  NaN    NaN   ...      \n",
       "4  Smith, Matt </O=ENRON/OU=NA/CN=RECIPIENTS/CN=M...  NaN    NaN   ...      \n",
       "\n",
       "  Cat_10_level_1 Cat_10_level_2 Cat_10_weight Cat_11_level_1 Cat_11_level_2  \\\n",
       "0            NaN            NaN           NaN            NaN            NaN   \n",
       "1            NaN            NaN           NaN            NaN            NaN   \n",
       "2            NaN            NaN           NaN            NaN            NaN   \n",
       "3            NaN            NaN           NaN            NaN            NaN   \n",
       "4            NaN            NaN           NaN            NaN            NaN   \n",
       "\n",
       "   Cat_11_weight  Cat_12_level_1  Cat_12_level_2  Cat_12_weight  labeled  \n",
       "0            NaN             NaN             NaN            NaN     True  \n",
       "1            NaN             NaN             NaN            NaN     True  \n",
       "2            NaN             NaN             NaN            NaN     True  \n",
       "3            NaN             NaN             NaN            NaN     True  \n",
       "4            NaN             NaN             NaN            NaN     True  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_complete = enron.pop('Complete')\n",
    "enron.insert(0, 'Complete', column_complete)\n",
    "enron.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset into a train and test set\n",
    "X = first 14 columns of the dataframe --> up to the user column\n",
    "\n",
    "y = the label columns. The remaining columns are all labels, except for the \"labeled\" column which is True for every sample.\n",
    "\n",
    "_For now, let's only look at the Cat level 2 column as our topic label. \n",
    "This column represents 8 different coarse genres:_\n",
    "* _1 Company Business, Strategy, etc. (855 cnt.)_\n",
    "* _2 Purely Personal (49 cnt.)_\n",
    "* _3 Personal but in professional context (e.g., it was good working with you) (165 cnt.)_\n",
    "* _4 Logistic Arrangements (meeting scheduling, technical support, etc) (533 cnt.)_\n",
    "* _5 Employment arrangements (job seeking, hiring, recommendations, etc) (96 cnt.)_\n",
    "* _6 Document editing/checking (collaboration) (176 cnt.)_\n",
    "* _7 Empty message (due to missing attachment) (25 cnt.)_\n",
    "* _8 Empty message (26 cnt.)_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(enron.iloc[:, 0:15], enron.iloc[:, 16], test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer, Tfidf Vectorizer, and Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(analyzer='word',\n",
    "                      ngram_range=(1,1),\n",
    "                      max_features=None,\n",
    "                      stop_words='english',\n",
    "                      min_df=2,\n",
    "                      max_df=0.95)\n",
    "\n",
    "train_counts = cvec.fit_transform(train_X.Complete)\n",
    "test_counts = cvec.transform(test_X.Complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfvec = TfidfVectorizer(analyzer='word',\n",
    "                       ngram_range=(1,1),\n",
    "                       max_features=None,\n",
    "                       stop_words='english',\n",
    "                       min_df=2,\n",
    "                       max_df=0.95)\n",
    "\n",
    "train_tf = tfvec.fit_transform(train_X['Complete'].fillna(''))\n",
    "test_tf = tfvec.transform(test_X['Complete'].fillna(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "Sklearn's documentation states that a count vectorizer should be more appropriate for this model. I will try both.\n",
    "\n",
    "First, count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bayes = MultinomialNB()\n",
    "n_bayes.fit(train_counts, train_y)\n",
    "\n",
    "n_bayes.score(test_counts, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5513196480938416"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bayes = MultinomialNB()\n",
    "n_bayes.fit(train_tf, train_y)\n",
    "\n",
    "n_bayes.score(test_tf, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tfidf seems to work a little bit better (Depending on the train test split, the tfidf outperforms by up to 4%). This makes sense, because the tfidf adds a weight factor for every word, and this is expected to be important to classification of text. It is interesting that the tfidf matrix works just as well, if not better, than the count matrix despite the documentation recommending the use of a count vector over tfidf.\n",
    "\n",
    "While the accuracy itself was not great, I am expecting better results from the version that does not include stopwords. Accuracy is also likely affected by the small sample size for both train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "We will try a few different versions of SVM.\n",
    "\n",
    "First is the standard 'svc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49560117302052786"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(train_counts, train_y)\n",
    "\n",
    "svm.score(test_counts, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49853372434017595"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(train_tf, train_y)\n",
    "\n",
    "svm.score(test_tf, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6070381231671554"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(train_counts, train_y)\n",
    "\n",
    "svm.score(test_counts, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7038123167155426"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(train_tf, train_y)\n",
    "\n",
    "svm.score(test_tf, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, SGDClassifier which uses gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fenes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6158357771260997"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SGDClassifier(loss='hinge')\n",
    "svm.fit(train_counts, train_y)\n",
    "\n",
    "svm.score(test_counts, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fenes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6832844574780058"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SGDClassifier(loss='hinge')\n",
    "svm.fit(train_tf, train_y)\n",
    "\n",
    "svm.score(test_tf, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Across multiple runs, the LinearSVC model outperforms the standard SVC model by upwards of 10%. The SGDClassifier is closer in accuracy, although LinearSVC still slightly outperforms it.\n",
    "\n",
    "Interestingly, the SGDClassifier's score can vary by over 9% for the same train/test samples. While the high-end of its scores can be around 66% for this dataset, its low end is closer to 50%. This variance makes the model unreliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "In other works dealing with text classification, logistic regression seems to perform somewhere between the LinearSVC and Multinomial Naive Bayes models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6774193548387096"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "log_reg.fit(train_tf, train_y)\n",
    "\n",
    "log_reg.score(test_tf, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Supervised Models with optimal parameters\n",
    "Above, I went through some models using mostly default values. I got decent results, but now I want to see how high each model can score if it uses optimal parameters.\n",
    "\n",
    "Luckily, sklearn provides a pretty easy way to do this. The main drawback, however, is that this method can be very slow.\n",
    "\n",
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Pipeline\n",
    "bayes_pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('bayes', MultinomialNB())])\n",
    "\n",
    "# Naive Bayes Parameters\n",
    "bayes_params = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'bayes__alpha': (1e-2, 1e-3)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch = GridSearchCV(bayes_pipeline, bayes_params, n_jobs=-1)\n",
    "gridSearch = gridSearch.fit(train_X['Complete'].fillna(' '), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6583394562821455\n",
      "{'bayes__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "print(gridSearch.best_score_)\n",
    "print(gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC Pipeline\n",
    "svc_pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('svm', SVC())])\n",
    "\n",
    "# SVC Parameters\n",
    "svc_params = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'svm__C': (0.2, 0.5, 1.0),\n",
    "              'svm__tol': (1e-2, 1e-3)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch = GridSearchCV(svc_pipeline, svc_params, n_jobs=-1)\n",
    "gridSearch = gridSearch.fit(train_X['Complete'].fillna(' '), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5033063923585599\n",
      "{'svm__C': 0.2, 'svm__tol': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "print(gridSearch.best_score_)\n",
    "print(gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearSVC Pipeline\n",
    "lin_svc_pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('svm', LinearSVC())])\n",
    "\n",
    "# LinearSVC Parameters\n",
    "lin_svc_params = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'svm__C': (0.2, 0.5, 1.0),\n",
    "                  'svm__tol': (1e-3, 1e-4),\n",
    "                  'svm__dual': (True, False)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch = GridSearchCV(lin_svc_pipeline, lin_svc_params, n_jobs=-1)\n",
    "gridSearch = gridSearch.fit(train_X['Complete'].fillna(' '), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6722997795738428\n",
      "{'svm__C': 1.0, 'svm__dual': True, 'svm__tol': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "print(gridSearch.best_score_)\n",
    "print(gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Pipeline\n",
    "sgd_pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('svm', SGDClassifier())])\n",
    "\n",
    "# SGD Parameters\n",
    "sgd_params = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'svm__alpha': (0.0005, 0.0001, 0.00008),\n",
    "                  'svm__loss': ('hinge', 'perceptron', 'modified_huber')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fenes\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "gridSearch = GridSearchCV(sgd_pipeline, sgd_params, n_jobs=-1)\n",
    "gridSearch = gridSearch.fit(train_X['Complete'].fillna(' '), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6700955180014695\n",
      "{'svm__alpha': 0.0005, 'svm__loss': 'hinge', 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(gridSearch.best_score_)\n",
    "print(gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Pipeline\n",
    "logreg_pipeline = Pipeline([('vect', CountVectorizer()),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('logreg', LogisticRegression())])\n",
    "\n",
    "# Logistic Regression Parameters\n",
    "logreg_params = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'logreg__tol': (1e-4, 1e-3),\n",
    "                  'logreg__solver': ('lbfgs', 'liblinear'),\n",
    "                  'logreg__class_weight': (None, 'balanced')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch = GridSearchCV(logreg_pipeline, logreg_params, n_jobs=-1)\n",
    "gridSearch = gridSearch.fit(train_X['Complete'].fillna(' '), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6700955180014695\n",
      "{'logreg__class_weight': 'balanced', 'logreg__solver': 'liblinear', 'logreg__tol': 0.0001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "print(gridSearch.best_score_)\n",
    "print(gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
