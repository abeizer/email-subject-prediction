{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset\n",
    "This enron dataset includes labels on 1700 of the emails. Information on how the dataset it labeled can be found [here](https://data.world/brianray/enron-email-dataset)\n",
    "\n",
    "Because only some of the emails are labeled, the first step is to save the labeled emails in their own file. This will be our working dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>...</th>\n",
       "      <th>Cat_10_level_1</th>\n",
       "      <th>Cat_10_level_2</th>\n",
       "      <th>Cat_10_weight</th>\n",
       "      <th>Cat_11_level_1</th>\n",
       "      <th>Cat_11_level_2</th>\n",
       "      <th>Cat_11_weight</th>\n",
       "      <th>Cat_12_level_1</th>\n",
       "      <th>Cat_12_level_2</th>\n",
       "      <th>Cat_12_weight</th>\n",
       "      <th>labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-05-14 23:39:00</td>\n",
       "      <td>frozenset({'phillip.allen@enron.com'})</td>\n",
       "      <td>frozenset({'tim.belden@enron.com'})</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-05-04 20:51:00</td>\n",
       "      <td>frozenset({'phillip.allen@enron.com'})</td>\n",
       "      <td>frozenset({'john.lavorato@enron.com'})</td>\n",
       "      <td>Re:</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>John J Lavorato &lt;John J Lavorato/ENRON@enronXg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;24216240.1075855687451.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2000-10-18 10:00:00</td>\n",
       "      <td>frozenset({'phillip.allen@enron.com'})</td>\n",
       "      <td>frozenset({'leah.arsdall@enron.com'})</td>\n",
       "      <td>Re: test</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Leah Van Arsdall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;13505866.1075863688222.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2000-10-23 13:13:00</td>\n",
       "      <td>frozenset({'phillip.allen@enron.com'})</td>\n",
       "      <td>frozenset({'randall.gay@enron.com'})</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Randall L Gay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;30922949.1075863688243.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2000-08-31 12:07:00</td>\n",
       "      <td>frozenset({'phillip.allen@enron.com'})</td>\n",
       "      <td>frozenset({'greg.piper@enron.com'})</td>\n",
       "      <td>Re: Hello</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Greg Piper</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Message-ID                 Date  \\\n",
       "0  <18782981.1075855378110.JavaMail.evans@thyme>  2001-05-14 23:39:00   \n",
       "1  <15464986.1075855378456.JavaMail.evans@thyme>  2001-05-04 20:51:00   \n",
       "2  <24216240.1075855687451.JavaMail.evans@thyme>  2000-10-18 10:00:00   \n",
       "3  <13505866.1075863688222.JavaMail.evans@thyme>  2000-10-23 13:13:00   \n",
       "4  <30922949.1075863688243.JavaMail.evans@thyme>  2000-08-31 12:07:00   \n",
       "\n",
       "                                     From  \\\n",
       "0  frozenset({'phillip.allen@enron.com'})   \n",
       "1  frozenset({'phillip.allen@enron.com'})   \n",
       "2  frozenset({'phillip.allen@enron.com'})   \n",
       "3  frozenset({'phillip.allen@enron.com'})   \n",
       "4  frozenset({'phillip.allen@enron.com'})   \n",
       "\n",
       "                                       To    Subject           X-From  \\\n",
       "0     frozenset({'tim.belden@enron.com'})        NaN  Phillip K Allen   \n",
       "1  frozenset({'john.lavorato@enron.com'})        Re:  Phillip K Allen   \n",
       "2   frozenset({'leah.arsdall@enron.com'})   Re: test  Phillip K Allen   \n",
       "3    frozenset({'randall.gay@enron.com'})        NaN  Phillip K Allen   \n",
       "4     frozenset({'greg.piper@enron.com'})  Re: Hello  Phillip K Allen   \n",
       "\n",
       "                                                X-To X-cc X-bcc  \\\n",
       "0           Tim Belden <Tim Belden/Enron@EnronXGate>  NaN   NaN   \n",
       "1  John J Lavorato <John J Lavorato/ENRON@enronXg...  NaN   NaN   \n",
       "2                                   Leah Van Arsdall  NaN   NaN   \n",
       "3                                      Randall L Gay  NaN   NaN   \n",
       "4                                         Greg Piper  NaN   NaN   \n",
       "\n",
       "                                            X-Folder   ...    Cat_10_level_1  \\\n",
       "0  \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...   ...               NaN   \n",
       "1  \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...   ...               NaN   \n",
       "2    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail   ...               NaN   \n",
       "3    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail   ...               NaN   \n",
       "4    \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail   ...               NaN   \n",
       "\n",
       "  Cat_10_level_2 Cat_10_weight Cat_11_level_1  Cat_11_level_2  Cat_11_weight  \\\n",
       "0            NaN           NaN            NaN             NaN            NaN   \n",
       "1            NaN           NaN            NaN             NaN            NaN   \n",
       "2            NaN           NaN            NaN             NaN            NaN   \n",
       "3            NaN           NaN            NaN             NaN            NaN   \n",
       "4            NaN           NaN            NaN             NaN            NaN   \n",
       "\n",
       "   Cat_12_level_1  Cat_12_level_2  Cat_12_weight  labeled  \n",
       "0             NaN             NaN            NaN    False  \n",
       "1             NaN             NaN            NaN    False  \n",
       "2             NaN             NaN            NaN    False  \n",
       "3             NaN             NaN            NaN    False  \n",
       "4             NaN             NaN            NaN    False  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_df = pd.read_csv('./enron.csv', low_memory=False, index_col=0)\n",
    "enron_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1702, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Subject</th>\n",
       "      <th>X-From</th>\n",
       "      <th>X-To</th>\n",
       "      <th>X-cc</th>\n",
       "      <th>X-bcc</th>\n",
       "      <th>X-Folder</th>\n",
       "      <th>...</th>\n",
       "      <th>Cat_10_level_1</th>\n",
       "      <th>Cat_10_level_2</th>\n",
       "      <th>Cat_10_weight</th>\n",
       "      <th>Cat_11_level_1</th>\n",
       "      <th>Cat_11_level_2</th>\n",
       "      <th>Cat_11_weight</th>\n",
       "      <th>Cat_12_level_1</th>\n",
       "      <th>Cat_12_level_2</th>\n",
       "      <th>Cat_12_weight</th>\n",
       "      <th>labeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;9831685.1075855725804.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-03-15 14:45:00</td>\n",
       "      <td>frozenset({'phillip.allen@enron.com'})</td>\n",
       "      <td>frozenset({'todd.burke@enron.com'})</td>\n",
       "      <td>Re: Confidential Employee Information/Lenhart</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Todd Burke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\Phillip_Allen_June2001\\Notes Folders\\'sent mail</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;21041312.1075855725847.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-03-15 14:11:00</td>\n",
       "      <td>frozenset({'phillip.allen@enron.com'})</td>\n",
       "      <td>frozenset({'kim.bolton@enron.com'})</td>\n",
       "      <td>RE: PERSONAL AND CONFIDENTIAL COMPENSATION INF...</td>\n",
       "      <td>Phillip K Allen</td>\n",
       "      <td>Kim Bolton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\Phillip_Allen_June2001\\Notes Folders\\'sent mail</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;5907100.1075858639941.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-06-20 17:04:51</td>\n",
       "      <td>frozenset({'k..allen@enron.com'})</td>\n",
       "      <td>frozenset({'matt.smith@enron.com', 'matthew.le...</td>\n",
       "      <td>FW: Western Wholesale Activities - Gas &amp; Power...</td>\n",
       "      <td>Allen, Phillip K. &lt;/O=ENRON/OU=NA/CN=RECIPIENT...</td>\n",
       "      <td>Lenhart, Matthew &lt;/O=ENRON/OU=NA/CN=RECIPIENTS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\PALLEN (Non-Privileged)\\Allen, Phillip K.\\Sen...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;26625142.1075858639964.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-06-20 17:09:00</td>\n",
       "      <td>frozenset({'k..allen@enron.com'})</td>\n",
       "      <td>frozenset({'matt.smith@enron.com', 'matthew.le...</td>\n",
       "      <td>FW: Western Wholesale Activities - Gas &amp; Power...</td>\n",
       "      <td>Allen, Phillip K. &lt;/O=ENRON/OU=NA/CN=RECIPIENT...</td>\n",
       "      <td>Lenhart, Matthew &lt;/O=ENRON/OU=NA/CN=RECIPIENTS...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\PALLEN (Non-Privileged)\\Allen, Phillip K.\\Sen...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;19730598.1075858642129.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>2001-08-09 12:30:58</td>\n",
       "      <td>frozenset({'k..allen@enron.com'})</td>\n",
       "      <td>frozenset({'matt.smith@enron.com', 'm..tholt@e...</td>\n",
       "      <td>FW: Western Wholesale Activities - Gas &amp; Power...</td>\n",
       "      <td>Allen, Phillip K. &lt;/O=ENRON/OU=NA/CN=RECIPIENT...</td>\n",
       "      <td>Smith, Matt &lt;/O=ENRON/OU=NA/CN=RECIPIENTS/CN=M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\PALLEN (Non-Privileged)\\Allen, Phillip K.\\Sen...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Message-ID                 Date  \\\n",
       "0   <9831685.1075855725804.JavaMail.evans@thyme>  2001-03-15 14:45:00   \n",
       "1  <21041312.1075855725847.JavaMail.evans@thyme>  2001-03-15 14:11:00   \n",
       "2   <5907100.1075858639941.JavaMail.evans@thyme>  2001-06-20 17:04:51   \n",
       "3  <26625142.1075858639964.JavaMail.evans@thyme>  2001-06-20 17:09:00   \n",
       "4  <19730598.1075858642129.JavaMail.evans@thyme>  2001-08-09 12:30:58   \n",
       "\n",
       "                                     From  \\\n",
       "0  frozenset({'phillip.allen@enron.com'})   \n",
       "1  frozenset({'phillip.allen@enron.com'})   \n",
       "2       frozenset({'k..allen@enron.com'})   \n",
       "3       frozenset({'k..allen@enron.com'})   \n",
       "4       frozenset({'k..allen@enron.com'})   \n",
       "\n",
       "                                                  To  \\\n",
       "0                frozenset({'todd.burke@enron.com'})   \n",
       "1                frozenset({'kim.bolton@enron.com'})   \n",
       "2  frozenset({'matt.smith@enron.com', 'matthew.le...   \n",
       "3  frozenset({'matt.smith@enron.com', 'matthew.le...   \n",
       "4  frozenset({'matt.smith@enron.com', 'm..tholt@e...   \n",
       "\n",
       "                                             Subject  \\\n",
       "0      Re: Confidential Employee Information/Lenhart   \n",
       "1  RE: PERSONAL AND CONFIDENTIAL COMPENSATION INF...   \n",
       "2  FW: Western Wholesale Activities - Gas & Power...   \n",
       "3  FW: Western Wholesale Activities - Gas & Power...   \n",
       "4  FW: Western Wholesale Activities - Gas & Power...   \n",
       "\n",
       "                                              X-From  \\\n",
       "0                                    Phillip K Allen   \n",
       "1                                    Phillip K Allen   \n",
       "2  Allen, Phillip K. </O=ENRON/OU=NA/CN=RECIPIENT...   \n",
       "3  Allen, Phillip K. </O=ENRON/OU=NA/CN=RECIPIENT...   \n",
       "4  Allen, Phillip K. </O=ENRON/OU=NA/CN=RECIPIENT...   \n",
       "\n",
       "                                                X-To X-cc X-bcc  \\\n",
       "0                                         Todd Burke  NaN   NaN   \n",
       "1                                         Kim Bolton  NaN   NaN   \n",
       "2  Lenhart, Matthew </O=ENRON/OU=NA/CN=RECIPIENTS...  NaN   NaN   \n",
       "3  Lenhart, Matthew </O=ENRON/OU=NA/CN=RECIPIENTS...  NaN   NaN   \n",
       "4  Smith, Matt </O=ENRON/OU=NA/CN=RECIPIENTS/CN=M...  NaN   NaN   \n",
       "\n",
       "                                            X-Folder   ...    Cat_10_level_1  \\\n",
       "0   \\Phillip_Allen_June2001\\Notes Folders\\'sent mail   ...               NaN   \n",
       "1   \\Phillip_Allen_June2001\\Notes Folders\\'sent mail   ...               NaN   \n",
       "2  \\PALLEN (Non-Privileged)\\Allen, Phillip K.\\Sen...   ...               NaN   \n",
       "3  \\PALLEN (Non-Privileged)\\Allen, Phillip K.\\Sen...   ...               NaN   \n",
       "4  \\PALLEN (Non-Privileged)\\Allen, Phillip K.\\Sen...   ...               NaN   \n",
       "\n",
       "  Cat_10_level_2 Cat_10_weight Cat_11_level_1  Cat_11_level_2  Cat_11_weight  \\\n",
       "0            NaN           NaN            NaN             NaN            NaN   \n",
       "1            NaN           NaN            NaN             NaN            NaN   \n",
       "2            NaN           NaN            NaN             NaN            NaN   \n",
       "3            NaN           NaN            NaN             NaN            NaN   \n",
       "4            NaN           NaN            NaN             NaN            NaN   \n",
       "\n",
       "   Cat_12_level_1  Cat_12_level_2  Cat_12_weight  labeled  \n",
       "0             NaN             NaN            NaN     True  \n",
       "1             NaN             NaN            NaN     True  \n",
       "2             NaN             NaN            NaN     True  \n",
       "3             NaN             NaN            NaN     True  \n",
       "4             NaN             NaN            NaN     True  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_df = enron_df.loc[enron_df['labeled'] == True]\n",
    "enron_df = enron_df.reset_index(drop=True)\n",
    "\n",
    "print(enron_df.shape)\n",
    "enron_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df.to_csv('./enron_labeled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods for Pre-Processing\n",
    "The email headers have already been broken down. The method used in this dataset is identical to the one used in our initial attempts at using the entire enron corpus. Emails are broken down into multiple fields, including To/From, a subject, content, and user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1702 entries, 0 to 1701\n",
      "Data columns (total 51 columns):\n",
      "Message-ID        1702 non-null object\n",
      "Date              1702 non-null object\n",
      "From              1702 non-null object\n",
      "To                1557 non-null object\n",
      "Subject           1636 non-null object\n",
      "X-From            1702 non-null object\n",
      "X-To              1567 non-null object\n",
      "X-cc              415 non-null object\n",
      "X-bcc             0 non-null object\n",
      "X-Folder          1702 non-null object\n",
      "X-Origin          1702 non-null object\n",
      "X-FileName        1700 non-null object\n",
      "content           1697 non-null object\n",
      "user              1702 non-null object\n",
      "Cat_1_level_1     1702 non-null float64\n",
      "Cat_1_level_2     1702 non-null float64\n",
      "Cat_1_weight      1702 non-null float64\n",
      "Cat_2_level_1     1506 non-null float64\n",
      "Cat_2_level_2     1506 non-null float64\n",
      "Cat_2_weight      1506 non-null float64\n",
      "Cat_3_level_1     1235 non-null float64\n",
      "Cat_3_level_2     1235 non-null float64\n",
      "Cat_3_weight      1235 non-null float64\n",
      "Cat_4_level_1     726 non-null float64\n",
      "Cat_4_level_2     726 non-null float64\n",
      "Cat_4_weight      726 non-null float64\n",
      "Cat_5_level_1     354 non-null float64\n",
      "Cat_5_level_2     354 non-null float64\n",
      "Cat_5_weight      354 non-null float64\n",
      "Cat_6_level_1     140 non-null float64\n",
      "Cat_6_level_2     140 non-null float64\n",
      "Cat_6_weight      140 non-null float64\n",
      "Cat_7_level_1     60 non-null float64\n",
      "Cat_7_level_2     60 non-null float64\n",
      "Cat_7_weight      60 non-null float64\n",
      "Cat_8_level_1     15 non-null float64\n",
      "Cat_8_level_2     15 non-null float64\n",
      "Cat_8_weight      15 non-null float64\n",
      "Cat_9_level_1     6 non-null float64\n",
      "Cat_9_level_2     6 non-null float64\n",
      "Cat_9_weight      6 non-null float64\n",
      "Cat_10_level_1    3 non-null float64\n",
      "Cat_10_level_2    3 non-null float64\n",
      "Cat_10_weight     3 non-null float64\n",
      "Cat_11_level_1    2 non-null float64\n",
      "Cat_11_level_2    2 non-null float64\n",
      "Cat_11_weight     2 non-null float64\n",
      "Cat_12_level_1    1 non-null float64\n",
      "Cat_12_level_2    1 non-null float64\n",
      "Cat_12_weight     1 non-null float64\n",
      "labeled           1702 non-null bool\n",
      "dtypes: bool(1), float64(36), object(14)\n",
      "memory usage: 666.6+ KB\n"
     ]
    }
   ],
   "source": [
    "enron_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I also need to know the base salaries of Jay Reitmeyer and Monique Sanchez. They are doing the same job as Matt.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_df['content'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk allows us to break text down into word tokens or sentences, depending on our goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I also need to know the base salaries of Jay Reitmeyer and Monique Sanchez.', 'They are doing the same job as Matt.']\n",
      "\n",
      "['I', 'also', 'need', 'to', 'know', 'the', 'base', 'salaries', 'of', 'Jay', 'Reitmeyer', 'and', 'Monique', 'Sanchez', '.', 'They', 'are', 'doing', 'the', 'same', 'job', 'as', 'Matt', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(enron_df['content'][0]))\n",
    "print()\n",
    "print(word_tokenize(enron_df['content'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopword Removal\n",
    "\n",
    "Stopword removal is important for getting rid of words that do not contribute to the overall meaning of the text. This will become important in later steps of our learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'do', 'so', 'those', 'needn', \"doesn't\", \"shouldn't\", 'you', 'after', 'that', 'ours', 'than', \"shan't\", 'above', 'm', 'out', 'yours', 'didn', 'hasn', 'until', 'below', 'this', 'doesn', 'no', 'now', \"didn't\", 'as', 'isn', 're', 'from', 'few', 'we', 'why', 'his', 'for', \"couldn't\", 'a', 'when', \"haven't\", 's', 'i', 'will', 'before', 'between', 'again', 'hadn', \"she's\", \"that'll\", 'mightn', 'further', \"aren't\", 'but', 'these', 'he', 'here', 'not', 'into', \"hadn't\", 'ma', 'theirs', 'can', 'only', 'haven', 'weren', 'too', 'it', 'their', 'yourself', 'were', 'with', 'having', 'them', 'her', 'did', 'doing', 'up', 'off', 'am', 'any', 'they', 'has', 'the', \"mightn't\", 'itself', 'herself', 'nor', 'which', 'just', 'should', 'down', 'she', 'while', 'on', 'other', 'where', 'shouldn', 'all', 'very', 'himself', 'your', 'd', 'each', 'to', 'y', 'ourselves', \"isn't\", 'shan', 'both', 'myself', 'won', 'is', \"wasn't\", \"hasn't\", \"you'll\", 'against', 've', 'of', 'hers', 'own', 'how', \"you're\", 'or', \"mustn't\", \"you'd\", 'wasn', 'yourselves', \"won't\", 'aren', 'who', 'o', 'themselves', \"don't\", 'have', 'through', \"needn't\", 't', 'had', 'some', 'been', 'over', 'whom', 'same', 'ain', 'because', 'under', 'mustn', 'most', 'being', 'once', \"you've\", 'me', 'my', 'by', 'wouldn', 'during', 'll', 'then', 'at', 'don', 'an', 'him', 'what', 'such', 'be', 'are', 'there', 'does', 'its', \"wouldn't\", 'more', 'was', 'our', 'and', 'about', \"it's\", \"should've\", 'in', 'couldn', \"weren't\", 'if'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging\n",
    "\n",
    "nltk offers part-of-speech tagging, which is hugely beneficial for certain applications. \n",
    "[Tag Definitions can be found here](https://pythonprogramming.net/natural-language-toolkit-nltk-part-speech-tagging/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # CC    coordinating conjunction\n",
    "        # CD    cardinal digit \n",
    "        # DT    determiner \n",
    "        # EX    existential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "        # FW    foreign word \n",
    "        # IN    preposition/subordinating conjunction\n",
    "        # JJ    adjective 'big'\n",
    "        # JJR   adjective, comparative 'bigger'\n",
    "        # JJS   adjective, superlative 'biggest'\n",
    "        # LS    list marker 1)\n",
    "        # MD    modal could, will\n",
    "        # NN    noun, singular 'desk'\n",
    "        # NNS   noun plural 'desks'\n",
    "        # NNP   proper noun, singular 'Harrison'\n",
    "        # NNPS  proper noun, plural 'Americans'\n",
    "        # PDT   predeterminer 'all the kids'\n",
    "        # POS   possessive ending parent's\n",
    "        # PRP   personal pronoun I, he, she\n",
    "        # PRP$  possessive pronoun my, his, hers\n",
    "        # RB    adverb very, silently, \n",
    "        # RBR   adverb, comparative better\n",
    "        # RBS   adverb, superlative best\n",
    "        # RP    particle give up\n",
    "        # TO    to go 'to' the store.\n",
    "        # UH    interjection errrrrrrrm\n",
    "        # VB    verb, base form take\n",
    "        # VBD   verb, past tense took\n",
    "        # VBG   verb, gerund/present participle taking\n",
    "        # VBN   verb, past participle taken\n",
    "        # VBP   verb, sing. present, non-3d take\n",
    "        # VBZ   verb, 3rd person sing. present takes\n",
    "        # WDT   wh-determiner which\n",
    "        # WP    wh-pronoun who, what\n",
    "        # WP$   possessive wh-pronoun whose\n",
    "        # WRB   wh-abverb where, when\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('also', 'RB'),\n",
       " ('need', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('know', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('base', 'JJ'),\n",
       " ('salaries', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('Jay', 'NNP'),\n",
       " ('Reitmeyer', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Monique', 'NNP'),\n",
       " ('Sanchez', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('They', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('doing', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('same', 'JJ'),\n",
       " ('job', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('Matt', 'NNP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(enron_df['content'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking and Chinking\n",
    "\n",
    "Chunking can be used to grab only certain parts of speech after a text has been tagged. For example, if we want to chunk for NNP (_Proper Noun_), we would do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkGram = r\"Chunk: {<NNP>+}\" # Regex that defines what a chunk is\n",
    "chunkParser = nltk.RegexpParser(chunkGram) # Turn our regex into a parser object\n",
    "\n",
    "for sentence in sent_tokenize(enron_df['content'][0]): # For each sentence in our text\n",
    "    tagged_words = nltk.pos_tag(word_tokenize(sentence)) # Tag the words in the sentence with part of speech\n",
    "    chunked = chunkParser.parse(tagged_words) # Run the chunkParser on the list of tagged words\n",
    "    \n",
    "    chunked.draw()\n",
    "    \n",
    "    # This will show the chunks visually for each sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you should see, combinations of first + last names are put into the same chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chinking is similar to chunking. The main difference is that while Chunking __includes__ terms, chinking will __exclude__ terms. If we want to try to remove any VB* (_Verbs_), IN (_Preposition_), and DT(_determiner_), we can get some good noun-phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunkGram = r\"\"\"Chunk: {<.*>+} \n",
    "                        }<VB.?|IN|DT|TO>+{\"\"\"\n",
    "chunkParser = nltk.RegexpParser(chunkGram)\n",
    "\n",
    "for sentence in sent_tokenize(enron_df['content'][0]): # For each sentence in our text\n",
    "    tagged_words = nltk.pos_tag(word_tokenize(sentence)) # Tag the words in the sentence with part of speech\n",
    "    chunked = chunkParser.parse(tagged_words) # Run the chunkParser on the list of tagged words\n",
    "    \n",
    "    chunked.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing\n",
    "\n",
    "Lemmatizing is a form of normalizing text. It reduces words down to their base lemma. For example, _runs_ and _running_ should reduce to the same lemma, _run_.\n",
    "\n",
    "The following example shows that lemmas depend on the word's part of speech. Therefore, lemmatization will be more accurate in retaining the original meaning of the text when used with nltk's part-of-speech tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun:\n",
      "run\n",
      "running\n",
      "\n",
      "adjective:\n",
      "runs\n",
      "running\n",
      "\n",
      "verb:\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(\"noun:\")\n",
    "print(lemmatizer.lemmatize(\"runs\", pos=\"n\"))\n",
    "print(lemmatizer.lemmatize(\"running\", pos=\"n\"))\n",
    "print()\n",
    "print(\"adjective:\")\n",
    "print(lemmatizer.lemmatize(\"runs\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"running\", pos=\"a\"))\n",
    "print()\n",
    "print(\"verb:\")\n",
    "print(lemmatizer.lemmatize(\"runs\", pos=\"v\"))\n",
    "print(lemmatizer.lemmatize(\"running\", pos=\"v\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using nltk's wordnet \n",
    "wordnet is essentially a dictionary of words. It can be used to look up a word's meaning, synonyms and antonyms, and other words that share the same base lemma. It can also be used to estimate the similarity of one word to another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synonyms and Antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('plan.n.01'),\n",
       " Synset('program.n.02'),\n",
       " Synset('broadcast.n.02'),\n",
       " Synset('platform.n.02'),\n",
       " Synset('program.n.05'),\n",
       " Synset('course_of_study.n.01'),\n",
       " Synset('program.n.07'),\n",
       " Synset('program.n.08'),\n",
       " Synset('program.v.01'),\n",
       " Synset('program.v.02')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List synonyms for a word\n",
    "syns = wordnet.synsets(\"program\")\n",
    "syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('broadcast.n.02')\n",
      "broadcast.n.02\n"
     ]
    }
   ],
   "source": [
    "# Access one word from the list (we will use broadcast for the following cells)\n",
    "print(syns[2])\n",
    "\n",
    "# Access the actual word rather than viewing it as a Synset\n",
    "print(syns[2].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('broadcast.n.02.broadcast'),\n",
       " Lemma('broadcast.n.02.program'),\n",
       " Lemma('broadcast.n.02.programme')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List lemmas for the synonym\n",
    "syns[2].lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'effective', 'trade_good', 'respectable', 'upright', 'ripe', 'estimable', 'unspoilt', 'expert', 'dear', 'secure', 'proficient', 'honorable', 'thoroughly', 'right', 'goodness', 'full', 'well', 'adept', 'salutary', 'dependable', 'undecomposed', 'practiced', 'unspoiled', 'in_force', 'serious', 'sound', 'honest', 'beneficial', 'near', 'soundly', 'skilful', 'commodity', 'good', 'in_effect', 'skillful', 'safe', 'just'}\n",
      "\n",
      "{'ill', 'badness', 'evilness', 'evil', 'bad'}\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "    \n",
    "print(set(synonyms))\n",
    "print()\n",
    "print(set(antonyms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Definitions and Use of a Word in a Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a radio or television show'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the word's definition\n",
    "syns[2].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['did you see his program last night?']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examples of the word's use in context\n",
    "syns[2].examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between 2 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Similarity between two words\n",
    "# Ship and Boat\n",
    "word1 = wordnet.synset(\"ship.n.01\")\n",
    "word2 = wordnet.synset(\"boat.n.01\")\n",
    "\n",
    "print(word1.wup_similarity(word2)) # These two words are 90% similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956521739130435\n"
     ]
    }
   ],
   "source": [
    "# Ship and Car\n",
    "word1 = wordnet.synset(\"ship.n.01\")\n",
    "word2 = wordnet.synset(\"car.n.01\")\n",
    "\n",
    "print(word1.wup_similarity(word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38095238095238093\n"
     ]
    }
   ],
   "source": [
    "# Ship and Cactus\n",
    "word1 = wordnet.synset(\"ship.n.01\")\n",
    "word2 = wordnet.synset(\"cactus.n.01\")\n",
    "\n",
    "print(word1.wup_similarity(word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n"
     ]
    }
   ],
   "source": [
    "# Ship and Cat\n",
    "word1 = wordnet.synset(\"ship.n.01\")\n",
    "word2 = wordnet.synset(\"cat.n.01\")\n",
    "\n",
    "print(word1.wup_similarity(word2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
