{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "The first data set we are going to analyze is the Enron Corpus.\n",
    "Because the corpus is so large, we really would not want to load all of the emails into python at once.\n",
    "Therefore, I have split the original csv, containing all 500k emails, into smaller files of about 10k emails each.\n",
    "I made sure that emails from a specific user's inbox are not split between multiple files. This should help later when we need to split up the Corpus into training and testing sets.<br/>\n",
    "<br/>\n",
    "We will start with loading the first chunk of the emails using pandas.<br/>\n",
    "Every cvs file has a header, telling pandas to record each email as two parts: a filename and the email's body.<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import email.utils\n",
    "import email\n",
    "import email.header\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10430, 2)\n"
     ]
    }
   ],
   "source": [
    "file = pd.read_csv(\"enron/initial/enron emails_chunk1.csv\")\n",
    "print(file.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having read the csv in, we can see the \"shape\" of the file.<br/>\n",
    "Here, we have 7942 emails, each with 2 fields: a filename and a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allen-p/_sent_mail/1.\n"
     ]
    }
   ],
   "source": [
    "print(file['file'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <32259460.1075852688586.JavaMail.evans@thyme>\r\n",
      "Date: Fri, 5 Oct 2001 01:31:17 -0700 (PDT)\r\n",
      "From: jennifer.fraser@enron.com\r\n",
      "To: john.arnold@enron.com\r\n",
      "Subject: RE: right about now dont u think u otta sell some calls against yr\r\n",
      " 36.88s\r\n",
      "Mime-Version: 1.0\r\n",
      "Content-Type: text/plain; charset=us-ascii\r\n",
      "Content-Transfer-Encoding: 7bit\r\n",
      "X-From: Fraser, Jennifer </O=ENRON/OU=NA/CN=RECIPIENTS/CN=JFRASER>\r\n",
      "X-To: Arnold, John </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Jarnold>\r\n",
      "X-cc: \r\n",
      "X-bcc: \r\n",
      "X-Folder: \\JARNOLD (Non-Privileged)\\Arnold, John\\Deleted Items\r\n",
      "X-Origin: Arnold-J\r\n",
      "X-FileName: JARNOLD (Non-Privileged).pst\r\n",
      "\r\n",
      "becuase we are overvalued .... jan01 37.50 2.90 bid\r\n",
      "\r\n",
      " -----Original Message-----\r\n",
      "From: \tArnold, John  \r\n",
      "Sent:\tThursday, October 04, 2001 10:25 PM\r\n",
      "To:\tFraser, Jennifer\r\n",
      "Subject:\tRE: right about now dont u think u otta sell some calls against yr 36.88s\r\n",
      "\r\n",
      "because we're $10 off the lows or because you think we're overvalued?\r\n",
      "\r\n",
      " -----Original Message-----\r\n",
      "From: \tFraser, Jennifer  \r\n",
      "Sent:\tThursday, October 04, 2001 11:23 AM\r\n",
      "To:\tArnold, John\r\n",
      "Subject:\tright about now dont u think u otta sell some calls against yr 36.88s\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(file['message'][5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking Down our Features\n",
    "\n",
    "Not all of the information from the emails will be helpful. This experiment focuses mainly on the content of the body, and we hypothesize that the senders, receivers, dates, etc. will not be useful in classifying their topics. Our first step is to remove this information from the body while retaining it in our dataframe in case they <i>do</i> end up being important for classification later on in the experiment.<br/>\n",
    "\n",
    "We will need to construct a new header for each .csv containing our complete set of features.<br/>\n",
    "When we are done, our features will be:\n",
    "<ul>\n",
    "    <li>filename</li>\n",
    "    <li>id</li>\n",
    "    <li>date</li>\n",
    "    <li>from</li>\n",
    "    <li>to</li>\n",
    "    <li>subject</li>\n",
    "    <li>cc</li>\n",
    "    <li>mime-version</li>\n",
    "    <li>content-type</li>\n",
    "    <li>content-encoding</li>\n",
    "    <li>bcc</li>\n",
    "    <li>message</li>\n",
    "</ul>\n",
    "Although there are fields in each email such as \"X-From\" \"X-To\" etc., these are redundant and it should be safe to disregard them without losing any data.<br/><br/>\n",
    "Let's make a function that will construct a header and add it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_header(filepath):\n",
    "    # The header containing our complete set of features\n",
    "    header = \"\\\"filename\\\",\\\"id\\\",\\\"date\\\",\\\"from\\\",\\\"to\\\",\\\"subject\\\",\\\"cc\\\",\\\"mime-version\\\",\\\"content-type\\\",\\\"content-encoding\\\",\\\"bcc\\\",\\\"message\\\"\\n\"\n",
    "\n",
    "    # Create a new file in the \"processed\" folder \n",
    "    # The filename should correspond to the given filepath.\n",
    "    f = open(os.path.join(\"enron/unlabeled\", os.path.basename(filepath)), \"w+\")\n",
    "    # Write the header to the file and print the first line of the file to confirm that the header is formatted correctly.\n",
    "    f.write(header)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write another function to take the lines from an email header and stick them into each of these features. This will be done by separating each feature with a comma inside the .csv.<br/>\n",
    "Our function will perform this action on all emails in a single chunk.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_features(filepath):\n",
    "    \n",
    "    # Read the file and collect all unprocessed emails\n",
    "    file = pd.read_csv(filepath)\n",
    "    \n",
    "    # Open the file in the \"processed\" folder.\n",
    "    # The filename should correspond to the given filepath.\n",
    "    f = open(os.path.join(\"enron/unlabeled\", os.path.basename(filepath)), \"a+\")\n",
    "    \n",
    "    # For each email in the chunk, separate the features and write to a new file.\n",
    "    for x in range(0, file.shape[0]):\n",
    "    \n",
    "        lines = file['message'][x].splitlines()\n",
    "    \n",
    "        # First comes the filename\n",
    "        f.write(\"\\\"\" + file['file'][0] + \"\\\",\")\n",
    "\n",
    "        # Every email has a message id\n",
    "        f.write(\"\\\"\" + lines[0] + \"\\\",\")\n",
    "\n",
    "        # Every email has a date\n",
    "        f.write(\"\\\"\" + lines[1] + \"\\\",\")\n",
    "\n",
    "        # Every email has a from line\n",
    "        f.write(\"\\\"\" + lines[2] + \"\\\",\")\n",
    "\n",
    "        # Every email has a to line\n",
    "        f.write(\"\\\"\" + lines[3] + \"\\\",\")\n",
    "\n",
    "        # Every email has a subject line, even though some are left blank\n",
    "        f.write(\"\\\"\" + lines[4] + \"\\\",\")\n",
    "\n",
    "        # Not every email has a cc line.\n",
    "        cc_line = 0\n",
    "        if lines[5].startswith('Cc'):\n",
    "            f.write(\"\\\"\" + lines[5] + \"\\\",\")\n",
    "            cc_line = 1\n",
    "        else:\n",
    "            f.write(\"\\\" \\\",\")\n",
    "\n",
    "        # Every email has a mime version\n",
    "        f.write(\"\\\"\" + lines[5 + cc_line] + \"\\\",\")\n",
    "\n",
    "        # Every email has a content-type\n",
    "        f.write(\"\\\"\" + lines[6 + cc_line] + \"\\\",\")\n",
    "\n",
    "        # Every email has a content-encoding\n",
    "        f.write(\"\\\"\" + lines[7 + cc_line] + \"\\\",\")\n",
    "\n",
    "        # Not email has a bcc line\n",
    "        bcc_line = 0\n",
    "        if lines[8 + cc_line].startswith('Bcc'):\n",
    "            f.write(\"\\\"\" + lines[8 + cc_line] + \"\\\",\")\n",
    "            bcc_line = 1\n",
    "        else:\n",
    "            f.write(\"\\\" \\\",\")\n",
    "\n",
    "        # Whatever remains is part of the message\n",
    "        f.write(\"\\\"\")\n",
    "        for i in range(9 + cc_line + bcc_line, len(lines)):\n",
    "            # We don't need to hold on to fields that start with X- because these are duplicated from the file header.\n",
    "            # These lines are only found in the current email, so it will not alter the content of email chains.\n",
    "            if lines[i].startswith(\"X-\"):\n",
    "                continue\n",
    "            f.write(lines[i].replace(\"\\\"\", \"\\\"\\\"\") + \"\\n\")\n",
    "        f.write(\"\\\"\\n\")\n",
    "        f.flush()\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test these methods on our first chunk and make sure the formatting is what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_header(\"enron/initial/enron emails_chunk1.csv\")\n",
    "separate_features(\"enron/initial/enron emails_chunk1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening the file visually looks good... Let's see if we can read it in using pandas without any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10427, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8868: expected 12 fields, saw 13\\nSkipping line 9197: expected 12 fields, saw 13\\nSkipping line 9380: expected 12 fields, saw 13\\n'\n"
     ]
    }
   ],
   "source": [
    "file = pd.read_csv(\"enron/unlabeled/enron emails_chunk1.csv\", error_bad_lines=False)\n",
    "print(file.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we've lost a couple of emails due to parsing errors. I need to look into this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <5705357.1075855920203.JavaMail.evans@thyme>\r\n",
      "Date: Wed, 9 Aug 2000 02:28:00 -0700 (PDT)\r\n",
      "From: sally.beck@enron.com\r\n",
      "To: mary.gray@enron.com\r\n",
      "Subject: Re: excitement\r\n",
      "Mime-Version: 1.0\r\n",
      "Content-Type: text/plain; charset=us-ascii\r\n",
      "Content-Transfer-Encoding: 7bit\r\n",
      "X-From: Sally Beck\r\n",
      "X-To: Mary Griff Gray\r\n",
      "X-cc: \r\n",
      "X-bcc: \r\n",
      "X-Folder: \\Sally_Beck_Dec2000\\Notes Folders\\'sent mail\r\n",
      "X-Origin: Beck-S\r\n",
      "X-FileName: sbeck.nsf\r\n",
      "\r\n",
      "It was great to see a friendly face!  Don't ever hesitate to wave or stop in \r\n",
      "and say hello.  Can you believe that I had been on the 30th floor since the \r\n",
      "summer of 1994?!  I know that sets some kind of record at Enron!!  It is kind \r\n",
      "of fun to be up here.  The appreciation for the jobs that we do in operations \r\n",
      "has grown over the last several years, thanks to the hard work of you and so \r\n",
      "many others.  \r\n",
      "\r\n",
      "My family is doing great.  The children start school tomorrow.  Meagan will \r\n",
      "be a junior in high school -- we took a brief trip with her this summer for \r\n",
      "an early look at some colleges.  It will be a big year for Amanda -- she \r\n",
      "starts junior high in 6th grade.  And Tyler would tell you proudly that he is \r\n",
      "\"two and a half\".  What a delight he continues to be!!  \r\n",
      " \r\n",
      "I know that Erin has worked hard.  I hope that she and her husband are doing \r\n",
      "well.  --Sally  \r\n",
      "\r\n",
      "\r\n",
      "   \r\n",
      "\r\n",
      "\r\n",
      "From:  Mary Griff Gray                                                        \r\n",
      "     08/08/2000 08:51 AM\t\r\n",
      "\t\r\n",
      "\t\r\n",
      "\t                           \r\n",
      "\t\r\n",
      "\r\n",
      "To: Sally Beck/HOU/ECT@ECT\r\n",
      "cc:  \r\n",
      "Subject: excitement\r\n",
      "\r\n",
      "Sally --\r\n",
      "\r\n",
      "I acted impulsively when I saw you this a.m.  I was so excited to know you \r\n",
      "were on the 33rd floor where I was picking up United Way shirts that I didn't \r\n",
      "control my enthusiasm over seeing you.\r\n",
      "\r\n",
      "I apologize if I disrupted you.\r\n",
      "\r\n",
      "Griff\r\n",
      "\r\n",
      "P.S.  I hope your family is doing fine.  Erin graduates in December from \r\n",
      "UT-Dallas with her masters in Speech Path.  She and her husband are doing \r\n",
      "very well and very much in love.\r\n",
      "\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(file['message'][347])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8785, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 993: expected 2 fields, saw 3\\nSkipping line 999: expected 2 fields, saw 3\\nSkipping line 1002: expected 2 fields, saw 3\\nSkipping line 1004: expected 2 fields, saw 3\\nSkipping line 1006: expected 2 fields, saw 3\\nSkipping line 1032: expected 2 fields, saw 3\\nSkipping line 1037: expected 2 fields, saw 3\\nSkipping line 1038: expected 2 fields, saw 3\\nSkipping line 1043: expected 2 fields, saw 3\\nSkipping line 1057: expected 2 fields, saw 3\\nSkipping line 1071: expected 2 fields, saw 3\\nSkipping line 1073: expected 2 fields, saw 3\\nSkipping line 1093: expected 2 fields, saw 3\\nSkipping line 1107: expected 2 fields, saw 3\\nSkipping line 1110: expected 2 fields, saw 3\\nSkipping line 1112: expected 2 fields, saw 3\\nSkipping line 1118: expected 2 fields, saw 3\\nSkipping line 1138: expected 2 fields, saw 3\\nSkipping line 1155: expected 2 fields, saw 3\\nSkipping line 1176: expected 2 fields, saw 3\\nSkipping line 1190: expected 2 fields, saw 3\\nSkipping line 1193: expected 2 fields, saw 3\\nSkipping line 1197: expected 2 fields, saw 3\\nSkipping line 1200: expected 2 fields, saw 3\\nSkipping line 1227: expected 2 fields, saw 3\\nSkipping line 1250: expected 2 fields, saw 3\\nSkipping line 1270: expected 2 fields, saw 3\\nSkipping line 1273: expected 2 fields, saw 3\\nSkipping line 1286: expected 2 fields, saw 3\\nSkipping line 1291: expected 2 fields, saw 3\\nSkipping line 1294: expected 2 fields, saw 3\\nSkipping line 1316: expected 2 fields, saw 3\\nSkipping line 1327: expected 2 fields, saw 3\\nSkipping line 1329: expected 2 fields, saw 4\\nSkipping line 1358: expected 2 fields, saw 3\\nSkipping line 1380: expected 2 fields, saw 3\\nSkipping line 1397: expected 2 fields, saw 4\\nSkipping line 1401: expected 2 fields, saw 3\\nSkipping line 1404: expected 2 fields, saw 3\\nSkipping line 1407: expected 2 fields, saw 3\\nSkipping line 1411: expected 2 fields, saw 3\\nSkipping line 1419: expected 2 fields, saw 3\\nSkipping line 1483: expected 2 fields, saw 3\\nSkipping line 1499: expected 2 fields, saw 3\\n'\n"
     ]
    }
   ],
   "source": [
    "file = pd.read_csv(\"enron/initial/enron emails_chunk42.csv\", error_bad_lines=False)\n",
    "print(file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
